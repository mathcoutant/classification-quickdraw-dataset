{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76583b2",
   "metadata": {},
   "source": [
    "# Classification based on Quickdraw Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc18d27",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0789760",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5035d93c3441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtyping_extensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mraise\u001b[0m  \u001b[1;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Base'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import cairocffi as cairo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import typing_extensions\n",
    "from importlib import reload\n",
    "reload(typing_extensions)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ab56d",
   "metadata": {},
   "source": [
    "### Functions for the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e370421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classes that will be used\n",
    "def load_classes(file_path):\n",
    "    res = {}\n",
    "    count = 0\n",
    "    for line in open(file_path, 'r'):\n",
    "        res[line.rstrip()] = count\n",
    "        count+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516c92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code is taken from the original GitHub of the QuickDrawDataset\n",
    "def vector_to_raster(vector_images, side=64, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=1)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "\n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2332ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the data as an array containing images as 1D arrays\n",
    "def load_data(sample, n_images, dimension):\n",
    "    sample_data = [json.loads(line) for line in open(f'data/full_simplified_{sample}.ndjson', 'r')]\n",
    "    sample_data = random.sample(sample_data, k=n_images)\n",
    "    vector_images = [drawing_data['drawing'] for drawing_data in sample_data]\n",
    "    return np.array(vector_to_raster(vector_images, side=dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d906aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the datasets as images in the \"images\" folder\n",
    "def save_png(drawing_class, data, dimension):\n",
    "    if not os.path.exists(f\"images/{drawing_class}\"): \n",
    "        os.makedirs(f\"images/{drawing_class}\")\n",
    "    \n",
    "    count = 0\n",
    "    for image_arr in data:\n",
    "        image_arr = np.reshape(image_arr, (dimension, -1))\n",
    "        img = Image.fromarray(image_arr, \"L\")\n",
    "        img.save(f\"images/{drawing_class}/axe_{count}.png\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09cf0f",
   "metadata": {},
   "source": [
    "### Functions for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8391a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b15a9bd",
   "metadata": {},
   "source": [
    "### Main part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab57ce",
   "metadata": {},
   "source": [
    "Variables describing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bcd9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images will be 64x64\n",
    "img_dim = 64\n",
    "# Number of images taken for each animal\n",
    "n_images = 2\n",
    "# Proportion used for to train the model\n",
    "train_prop = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e76da2",
   "metadata": {},
   "source": [
    "Store the classes in a dictionnary with their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a44a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'axe': 0, 'bicycle': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = load_classes(\"class_names.txt\")\n",
    "n_class = len(classes)\n",
    "print(n_class)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f8a54",
   "metadata": {},
   "source": [
    "Build the different sets from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "749b0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = []\n",
    "data_Y = []\n",
    "for drawing_class in classes:\n",
    "    data = load_data(drawing_class, n_images, dimension = img_dim)\n",
    "    data_X.append(data)\n",
    "    data_Y.append(np.full(n_images, classes[drawing_class]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# maybe not necesssary\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(data_X, data_Y, train_size = train_prop, random_state = 42, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std_dev)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_data, transform=preprocess)\n",
    "test_dataset = Dataset(test_data, transform=preprocess)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size = , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec90670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00552653",
   "metadata": {},
   "source": [
    "For the datas :\n",
    "- load in arrays\n",
    "- sort to keep only the recognized drawings\n",
    "- (save the arrays)\n",
    "- (possibility to save in png)\n",
    "- faire des sets de tests et train\n",
    "\n",
    "For the CNN:\n",
    "- (batch normailzation)\n",
    "- conv relu pooling conv relu pooling dropout\n",
    "\n",
    "For vizualization and documentation:\n",
    "- Confusion Matrix\n",
    "- evolution of the error with epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5184791",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bd913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
