{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76583b2",
   "metadata": {},
   "source": [
    "# Classification based on Quickdraw Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc18d27",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0789760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import cairocffi as cairo\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image, ImageReadMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ab56d",
   "metadata": {},
   "source": [
    "### Functions to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e370421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classes that will be used\n",
    "def load_classes(file_path):\n",
    "    res = {}\n",
    "    count = 0\n",
    "    for line in open(file_path, 'r'):\n",
    "        res[count] = line.rstrip()\n",
    "        count+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516c92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code is taken from the original GitHub of the QuickDrawDataset\n",
    "def vector_to_raster(vector_images, side=64, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=1)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "\n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2332ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the data as an array containing images as 1D arrays\n",
    "def load_data(sample, n_images, dimension):\n",
    "    sample_data = [json.loads(line) for line in open(f'data/full_simplified_{sample}.ndjson', 'r')]\n",
    "    sample_data = random.sample(sample_data, k=n_images)\n",
    "    vector_images = [drawing_data['drawing'] for drawing_data in sample_data]\n",
    "    return np.array(vector_to_raster(vector_images, side=dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d906aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the datasets as images in the \"images\" folder\n",
    "def save_png(drawing_class, data, dimension):\n",
    "    if not os.path.exists(f\"images/{drawing_class}\"): \n",
    "        os.makedirs(f\"images/{drawing_class}\")\n",
    "\n",
    "    count = 0\n",
    "    for image_arr in data:\n",
    "        image_arr = np.reshape(image_arr, (dimension, -1))\n",
    "        img = Image.fromarray(image_arr, \"L\")\n",
    "        img.save(f\"images/{drawing_class}/{drawing_class}_{count}.png\")\n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ead76647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(classes, n_images, img_dim, train_prop=0.8, save_images = False):\n",
    "  data_X = [] # To get the mean and standard deviation of the images\n",
    "  train_file_names = []\n",
    "  train_labels = []\n",
    "  test_file_names = []\n",
    "  test_labels = []\n",
    "  \n",
    "  for key, drawing_class in classes.items():\n",
    "      print(f\"Loading {drawing_class} data\")\n",
    "      data = load_data(drawing_class, n_images, dimension = img_dim)\n",
    "      data_X.append(data)\n",
    "      if(save_images):\n",
    "        save_png(drawing_class, data, img_dim)\n",
    "      file_names = [f\"images/{drawing_class}/{drawing_class}_{i}.png\" for i in range(len(data))]\n",
    "      labels = np.full(len(data), key)\n",
    "      train_file_names.append(file_names[:(int)(n_images*train_prop)])\n",
    "      train_labels.append(labels[:(int)(n_images*train_prop)])\n",
    "      test_file_names.append(file_names[(int)(n_images*train_prop):])\n",
    "      test_labels.append(labels[(int)(n_images*train_prop):])\n",
    "  \n",
    "  # Compute the mean and standard deviation of the images\n",
    "  data_X = np.array(data_X)\n",
    "  mean = np.mean(data_X)\n",
    "  std = np.std(data_X)\n",
    "\n",
    "  # Save the file names and labels\n",
    "  train_file_names = np.array(train_file_names).flatten()\n",
    "  json.dump(train_file_names.tolist(), open(\"train_file_names.json\", 'w'))\n",
    "  train_labels = np.array(train_labels).flatten()\n",
    "  json.dump(train_labels.tolist(), open(\"train_labels.json\", 'w'))\n",
    "  test_file_names = np.array(test_file_names).flatten()\n",
    "  json.dump(test_file_names.tolist(), open(\"test_file_names.json\", 'w'))\n",
    "  test_labels = np.array(test_labels).flatten()\n",
    "  json.dump(test_labels.tolist(), open(\"test_labels.json\", 'w'))\n",
    "  \n",
    "  return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba1702",
   "metadata": {},
   "source": [
    "### Dataset class the represent the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "555f9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickDrawDataset(Dataset):\n",
    "    def __init__(self, file_names, labels, transform=None):\n",
    "        self.file_names = file_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = read_image(self.file_names[idx], mode=ImageReadMode.GRAY)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09cf0f",
   "metadata": {},
   "source": [
    "### Functions for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8391a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b15a9bd",
   "metadata": {},
   "source": [
    "### Main part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab57ce",
   "metadata": {},
   "source": [
    "Variables describing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcd9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images will be 64x64\n",
    "img_dim = 64\n",
    "# Number of images taken for each animal\n",
    "n_images = 2\n",
    "# Proportion used for to train the model\n",
    "train_prop = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e76da2",
   "metadata": {},
   "source": [
    "Store the classes in a dictionnary with their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a44a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'axe', 1: 'bicycle'}\n"
     ]
    }
   ],
   "source": [
    "classes = load_classes(\"class_names.txt\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f8a54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The preprocess function do multiple thingd : <br>\n",
    "- Build the png images from the json files. Like this the PyTorch Dataset object will search the images directly in the files\n",
    "- Separate the dataset in train and test datasets by storing the names of the \n",
    "- Process the mean and the standard deviation and return it to later normalize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "749b0f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading axe data\n",
      "Loading bicycle data\n"
     ]
    }
   ],
   "source": [
    "mean, std = preprocess_data(classes, n_images=5, img_dim=64, train_prop=train_prop, save_images = False)\n",
    "\n",
    "train_files = json.load(open(\"train_file_names.json\", 'r'))\n",
    "test_files = json.load(open(\"test_file_names.json\", 'r'))\n",
    "train_labels = json.load(open(\"train_labels.json\", 'r'))\n",
    "test_labels = json.load(open(\"test_labels.json\", 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb54f4b",
   "metadata": {},
   "source": [
    "Create the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc81e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "train_dataset = QuickDrawDataset(train_files, train_labels, transform=preprocess)\n",
    "test_dataset = QuickDrawDataset(test_files, test_labels, transform=preprocess)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec90670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00552653",
   "metadata": {},
   "source": [
    "For the datas :\n",
    "- load in arrays\n",
    "- sort to keep only the recognized drawings\n",
    "- (save the arrays)\n",
    "- (possibility to save in png)\n",
    "- faire des sets de tests et train\n",
    "\n",
    "For the CNN:\n",
    "- (batch normailzation)\n",
    "- conv relu pooling conv relu pooling dropout\n",
    "\n",
    "For vizualization and documentation:\n",
    "- Confusion Matrix\n",
    "- evolution of the error with epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5184791",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bd913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
